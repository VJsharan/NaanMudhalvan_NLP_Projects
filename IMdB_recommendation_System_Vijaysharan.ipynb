{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Code to create the dataset\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Movie_Name': [\n",
        "        'The Wizard’s Quest', 'Starlight Chronicles', 'The Dark Sorcerer', 'Moonlit Shadows',\n",
        "        'Galactic Pioneers', 'Time Loop', 'The Magic Academy', 'Desert Nomads',\n",
        "        'Cyber Rebellion', 'The Lost Kingdom', 'Echoes of Eternity', 'Skyward Bound',\n",
        "        'The Phantom Thief', 'Ocean’s Secret', 'The Fire Within', 'Quantum Voyage',\n",
        "        'The Enchanted Forest', 'Nightmare’s End', 'The Last Guardian', 'Cosmic Dawn'\n",
        "    ],\n",
        "    'Storyline': [\n",
        "        'A young wizard uncovers a hidden prophecy and battles a dark sorcerer to save his realm.',\n",
        "        'A group of explorers discovers a mystical star that holds the key to the universe’s secrets.',\n",
        "        'A hero confronts an ancient sorcerer threatening to plunge the world into darkness.',\n",
        "        'A detective investigates a series of mysterious disappearances under the moon’s eerie glow.',\n",
        "        'Astronauts explore a distant planet, uncovering alien technology and hidden dangers.',\n",
        "        'A scientist trapped in a time loop must solve a puzzle to prevent a global catastrophe.',\n",
        "        'Students at a magical academy face challenges and rivalries while mastering their powers.',\n",
        "        'A lone wanderer leads a tribe through a harsh desert to find a fabled oasis.',\n",
        "        'Hackers lead a rebellion against a dystopian regime controlling the world’s data.',\n",
        "        'An adventurer seeks a lost kingdom buried beneath the sands of time.',\n",
        "        'A poet hears voices from the past, guiding her to uncover a forgotten civilization.',\n",
        "        'Pilots in a futuristic air race uncover a conspiracy threatening global peace.',\n",
        "        'A cunning thief pulls off heists while evading a relentless detective.',\n",
        "        'A marine biologist discovers a hidden underwater city with ancient secrets.',\n",
        "        'A firefighter with a troubled past finds redemption battling a massive inferno.',\n",
        "        'A crew on a quantum-powered ship navigates uncharted dimensions to return home.',\n",
        "        'A child enters a magical forest where mythical creatures guard a powerful artifact.',\n",
        "        'A psychologist helps a patient confront nightmares that turn out to be real threats.',\n",
        "        'The last of an ancient order protects a sacred relic from a ruthless warlord.',\n",
        "        'A new star appears in the sky, triggering events that could reshape the cosmos.'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create DataFrame and save to CSV\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('movies.csv', index=False)\n",
        "print(\"Dataset created and saved as 'movies.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfRDYrEDDm1B",
        "outputId": "8e693d4d-3f66-43c3-820a-4afc5f79e926"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created and saved as 'movies.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install streamlit pyngrok nltk pandas numpy scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import streamlit as st\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Load dataset from CSV\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    try:\n",
        "        df = pd.read_csv('movies.csv')\n",
        "        if 'Movie_Name' not in df.columns or 'Storyline' not in df.columns:\n",
        "            raise ValueError(\"CSV must contain 'Movie_Name' and 'Storyline' columns\")\n",
        "        df['Processed_Storyline'] = df['Storyline'].apply(preprocess_text)\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        st.error(\"movies.csv not found. Please upload the CSV file.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "# Write Streamlit app to file\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write('''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import streamlit as st\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    try:\n",
        "        df = pd.read_csv('movies.csv')\n",
        "        if 'Movie_Name' not in df.columns or 'Storyline' not in df.columns:\n",
        "            raise ValueError(\"CSV must contain 'Movie_Name' and 'Storyline' columns\")\n",
        "        df['Processed_Storyline'] = df['Storyline'].apply(preprocess_text)\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        st.error(\"movies.csv not found. Please upload the CSV file.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "st.title('Movie Recommendation System')\n",
        "st.write('Enter a movie storyline to get recommendations')\n",
        "\n",
        "df = load_data()\n",
        "if df is not None:\n",
        "    tfidf = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf.fit_transform(df['Processed_Storyline'])\n",
        "\n",
        "    user_input = st.text_area('Enter a movie storyline:',\n",
        "                            'A young wizard begins his journey at a magical school where he makes friends and enemies, facing dark forces along the way')\n",
        "\n",
        "    if st.button('Get Recommendations'):\n",
        "        processed_input = preprocess_text(user_input)\n",
        "        user_tfidf = tfidf.transform([processed_input])\n",
        "        cosine_sim = cosine_similarity(user_tfidf, tfidf_matrix)\n",
        "        sim_scores = list(enumerate(cosine_sim[0]))\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "        top_5_indices = [i[0] for i in sim_scores[:5]]\n",
        "\n",
        "        st.subheader('Top 5 Recommended Movies:')\n",
        "        for idx in top_5_indices:\n",
        "            st.write(f\"**{df['Movie_Name'].iloc[idx]}**\")\n",
        "            st.write(f\"Storyline: {df['Storyline'].iloc[idx]}\")\n",
        "            st.write(\"---\")\n",
        "    ''')\n",
        "\n",
        "# Kill existing ngrok and Streamlit processes\n",
        "!pkill ngrok\n",
        "!pkill streamlit\n",
        "\n",
        "# Set ngrok auth token\n",
        "try:\n",
        "    !ngrok authtoken 2wVNj1AoLAIlz9SqQ6Zg6lQ4iks_469cNo7ocrA6Ny2CftnQx # Replace with your actual token\n",
        "    print(\"ngrok auth token set successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to set ngrok auth token: {e}\")\n",
        "    raise\n",
        "\n",
        "# Start ngrok tunnel\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"ngrok tunnel started at: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to start ngrok: {e}\")\n",
        "    raise\n",
        "\n",
        "# Start Streamlit in the background\n",
        "try:\n",
        "    process = subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port=8501'])\n",
        "    print(\"Streamlit server started. Waiting for it to be ready...\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to start Streamlit: {e}\")\n",
        "    raise\n",
        "\n",
        "# Wait for Streamlit to start\n",
        "time.sleep(10)  # Increased to 10 seconds for stability\n",
        "\n",
        "# Check if Streamlit is running\n",
        "try:\n",
        "    result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)\n",
        "    if 'streamlit' in result.stdout:\n",
        "        print(\"Streamlit is running. Access it at the ngrok URL above.\")\n",
        "    else:\n",
        "        print(\"Streamlit failed to start. Check for errors in the Streamlit output.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error checking Streamlit process: {e}\")\n",
        "\n",
        "# Check if movies.csv exists\n",
        "try:\n",
        "    with open('movies.csv', 'r') as f:\n",
        "        print(\"movies.csv found in the current directory.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"movies.csv not found. Please run the dataset creation code first.\")\n",
        "\n",
        "# Keep the cell running to maintain the tunnel\n",
        "try:\n",
        "    input(\"Press Enter to stop the server and tunnel...\")\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopping server and tunnel...\")\n",
        "finally:\n",
        "    ngrok.kill()\n",
        "    process.terminate()\n",
        "    print(\"Server and tunnel stopped.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw3_O1RoDngY",
        "outputId": "1a3fa8a6-723c-4eb5-aa17-4cc810f6595b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "2025-05-01 18:17:34.374 No runtime found, using MemoryCacheStorageManager\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "ngrok auth token set successfully\n",
            "ngrok tunnel started at: NgrokTunnel: \"https://f6b4-34-106-40-163.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "Streamlit server started. Waiting for it to be ready...\n",
            "Streamlit is running. Access it at the ngrok URL above.\n",
            "movies.csv found in the current directory.\n",
            "Press Enter to stop the server and tunnel...\n",
            "Server and tunnel stopped.\n"
          ]
        }
      ]
    }
  ]
}